# Connaître les limites des données
Il est indispensable de connaître les limites des données afin de maîtriser l’incertitude de l’analyse ; les résultats ne sont jamais parfaitement fiables.  

Il y a plusieurs sources d’imprécision :
* L’imperfection des indicateurs ;
* La fluctuation naturelles des données ;
* L’évolutions de l’impact de l’action dans de temps ;
* Les biais de sélections sur les retours des utilisateurs.

Un indicateur ne mesure qu’imparfaitement un objectif ; il y a toujours un écart versatile entre ce que mesure l’indicateur et la vraie valeur de l’objectif. Par exemple, si l’on mesure un phénomène indirectement (connaître l’état psychologique des utilisateurs, à quel point ils sont convaincus par l’offre, attachés à la marque, …). Aussi car l’indicateur ne mesure que le chemin le plus courant des utilisateurs (mesurer l’impact d’une campagne web marketing en regardant les clics qu’elle amène occultent une certains vont chercher la marque sur un moteur de recherche ou saisissent l’URL directement). Un courriel peut avoir un impact au-delà des clics qu’il a généré (les utilisateurs reviennent ultérieurement sur les site, continuant à y penser). Également, si la valeur mesurée est corrigée à postériori (notamment pour les ventes pouvant être annulées, remboursées, ajoutées après coup en cas de bogue, …).

Dans le monde, les indicateurs fluctuent en permanence à cause d’un très grand nb de facteurs. Ce qui les rends plus ou moins importantes indépendamment de notre action. Dont, celles d’autres actions en cours dans l’entreprise avec un impact direct à court, moyen ou long terme. Aussi la météo, l’économie, et d’autres variations aléatoires faisant que le nombre de connexion change tous les jours…  
Ces fluctuations compliquent le travail, si on utilise le passé en base de comparaison. La courbe pourrait être différente ou non sans notre action (une autre équipe peut avoir un effet secondaire, …). Le seul moyen d’éliminer se biais est l’AB test, mais limité par ce qui mis en place dans la population de contrôle.  

A/B test ou non, les conclusions peuvent ne pas correctement d’écrire l’impact d’une action dans le temps. Il est facile de déduire que la saisonnalité impact le comportement des utilisateurs, ce qui impact notre action. La nouveauté a aussi un impact, car les utilisateurs peuvent êtres réfractaires au changement (l’action se remarquerai au long terme) ou attirer par la nouveauté (l’impact est plus important au début), dans une même population, il y a les deux ; l’effet global est alors assez difficile à prévoir. Le biais de sélection impact les retours utilisateurs.

Finalement, il faut être attentif à ce biais de sélection. Les utilisateurs volontaires pour répondre à un questionnaire, faire des tests, ou contactent le service client sont très motivés. Leur retour ne peut pas illustrer parfaitement la majorité.

On part généralement du fait que ceci a un impact assez faible pour ne pas changer la conclusion ; le résultat est plus directionnel que précis ; que l’action a eu un impact positif est plutôt important. Il faut garder en tête cette incertitude si d’autres occasions de présentent pour changer les conclusions.